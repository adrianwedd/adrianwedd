name: 🧪 Comprehensive Test Suite Excellence

on:
  pull_request:
    branches: [ main ]
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test coverage level'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - quick
          - performance-only

env:
  CI: true
  NODE_ENV: test

jobs:
  pre-test-analysis:
    name: 📊 Pre-Test Analysis & Setup
    runs-on: ubuntu-latest
    outputs:
      test-strategy: ${{ steps.strategy.outputs.strategy }}
      file-count: ${{ steps.analysis.outputs.file-count }}
      complexity-score: ${{ steps.analysis.outputs.complexity }}
    steps:
      - name: 🚀 Test Suite Initialization
        run: |
          echo "🧪 **COMPREHENSIVE TEST SUITE INITIATED**"
          echo "📅 Started at: $(date +'%Y-%m-%d %H:%M:%S UTC')"
          echo "🎯 Test level: ${{ github.event.inputs.test_level || 'full' }}"
          echo "🌿 Branch: ${{ github.ref_name }}"
          echo "💫 Commit: ${{ github.sha }}"
          echo "🤖 Triggered by: ${{ github.event_name }}"
          echo ""
          
          # Initialize CI logging
          mkdir -p logs/ci
          LOG_FILE="logs/ci/test-suite-$(date +'%Y%m%d-%H%M%S').log"
          echo "📝 Initializing CI log: $LOG_FILE"
          
          {
            echo "🧪 COMPREHENSIVE TEST SUITE LOG"
            echo "======================================"
            echo "📅 Started: $(date +'%Y-%m-%d %H:%M:%S UTC')"
            echo "🎯 Test level: ${{ github.event.inputs.test_level || 'full' }}"
            echo "🌿 Branch: ${{ github.ref_name }}"
            echo "💫 Commit: ${{ github.sha }}"
            echo "🤖 Triggered by: ${{ github.event_name }}"
            echo ""
          } > "$LOG_FILE"
          
          echo "ci_log_file=$LOG_FILE" >> $GITHUB_ENV

      - name: 📥 Repository Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: 🔍 Codebase Analysis
        id: analysis
        run: |
          echo "🔬 **ANALYZING CODEBASE COMPLEXITY**"
          
          # Count different file types
          JS_FILES=$(find . -name "*.js" -not -path "./node_modules/*" | wc -l)
          TS_FILES=$(find . -name "*.ts" -not -path "./node_modules/*" | wc -l)
          CSS_FILES=$(find . -name "*.css" -not -path "./node_modules/*" | wc -l)
          HTML_FILES=$(find . -name "*.html" -not -path "./node_modules/*" | wc -l)
          TEST_FILES=$(find . -name "*.test.*" -o -name "*.spec.*" -not -path "./node_modules/*" | wc -l)
          
          TOTAL_FILES=$((JS_FILES + TS_FILES + CSS_FILES + HTML_FILES))
          
          echo "📁 **File Analysis:**"
          echo "  - JavaScript files: $JS_FILES"
          echo "  - TypeScript files: $TS_FILES" 
          echo "  - CSS files: $CSS_FILES"
          echo "  - HTML files: $HTML_FILES"
          echo "  - Test files: $TEST_FILES"
          echo "  - Total source files: $TOTAL_FILES"
          
          # Calculate complexity score (simple heuristic)
          COMPLEXITY_SCORE=$((TOTAL_FILES * 2 + TEST_FILES * 3))
          
          echo "📊 Complexity score: $COMPLEXITY_SCORE"
          echo "file-count=$TOTAL_FILES" >> $GITHUB_OUTPUT
          echo "complexity=$COMPLEXITY_SCORE" >> $GITHUB_OUTPUT
          echo ""

      - name: 🎯 Test Strategy Selection
        id: strategy
        run: |
          echo "🎲 **DETERMINING OPTIMAL TEST STRATEGY**"
          
          COMPLEXITY=${{ steps.analysis.outputs.complexity }}
          TEST_LEVEL="${{ github.event.inputs.test_level || 'full' }}"
          
          if [ "$TEST_LEVEL" = "quick" ] || [ "$COMPLEXITY" -lt 50 ]; then
            STRATEGY="quick"
            echo "⚡ Selected: Quick test strategy (complexity: $COMPLEXITY)"
          elif [ "$TEST_LEVEL" = "performance-only" ]; then
            STRATEGY="performance"
            echo "📈 Selected: Performance-only strategy"
          else
            STRATEGY="comprehensive"
            echo "🔬 Selected: Comprehensive test strategy (complexity: $COMPLEXITY)"
          fi
          
          echo "strategy=$STRATEGY" >> $GITHUB_OUTPUT
          echo ""

  lint:
    name: 🔍 Code Quality & Standards
    runs-on: ubuntu-latest
    needs: pre-test-analysis
    steps:
      - name: 🎨 Linting Phase Initialization
        run: |
          echo "🔍 **CODE QUALITY ANALYSIS INITIATED**"
          echo "📊 Analyzing ${{ needs.pre-test-analysis.outputs.file-count }} source files"
          echo "🎯 Complexity score: ${{ needs.pre-test-analysis.outputs.complexity-score }}"
          echo ""

      - name: 📥 Repository Checkout
        uses: actions/checkout@v4

      - name: ⚙️ Node.js Environment Setup
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: 📦 Dependency Installation
        run: |
          echo "📦 **INSTALLING PROJECT DEPENDENCIES**"
          npm ci --prefer-offline --no-audit
          echo "✅ Dependencies installed successfully"
          echo ""

      - name: 🔍 ESLint Analysis
        run: |
          echo "🔍 **RUNNING ESLINT ANALYSIS**"
          echo "📋 Checking JavaScript/TypeScript code quality..."
          npm run lint 2>&1 | tee eslint-output.log || {
            echo "❌ ESLint found issues - see details above"
            exit 1
          }
          echo "✅ ESLint analysis completed successfully"
          echo ""
          
          # Log to persistent file
          {
            echo "🔍 ESLint Analysis: SUCCESS"
            echo "📅 $(date +'%Y-%m-%d %H:%M:%S UTC')"
            echo "📊 Files analyzed: JavaScript/TypeScript"
            echo ""
          } >> "${{ env.ci_log_file }}"

      - name: ✨ Code Formatting Validation
        run: |
          echo "✨ **VALIDATING CODE FORMATTING**"
          echo "📐 Checking Prettier formatting compliance..."
          npm run format-check 2>&1 | tee prettier-output.log || {
            echo "❌ Code formatting issues detected"
            echo "💡 Run 'npm run format' to fix formatting"
            exit 1
          }
          echo "✅ Code formatting validation passed"
          echo ""

      - name: 🎨 CSS Lint Validation
        run: |
          echo "🎨 **VALIDATING CSS STYLES**"
          echo "🖌️ Checking CSS/SCSS style compliance..."
          npm run lint:css 2>&1 | tee stylelint-output.log || {
            echo "❌ CSS linting issues detected"
            exit 1
          }
          echo "✅ CSS validation completed successfully"
          echo ""

      - name: 📊 Linting Summary
        if: always()
        run: |
          echo "📋 **CODE QUALITY SUMMARY**"
          echo "✅ ESLint: ${{ job.steps.eslint.outcome == 'success' && 'PASSED' || 'FAILED' }}"
          echo "✅ Prettier: ${{ job.steps.prettier.outcome == 'success' && 'PASSED' || 'FAILED' }}"  
          echo "✅ Stylelint: ${{ job.steps.stylelint.outcome == 'success' && 'PASSED' || 'FAILED' }}"
          echo ""
      
  test:
    name: 🚀 Comprehensive Testing Suite
    runs-on: ubuntu-latest
    needs: [pre-test-analysis, lint]
    strategy:
      matrix:
        test-type: [unit, e2e, accessibility, mobile]
      fail-fast: false
    steps:
      - name: 🎯 Test Phase Initialization
        run: |
          echo "🧪 **${{ matrix.test-type }} TESTING PHASE INITIATED**"
          echo "📊 Strategy: ${{ needs.pre-test-analysis.outputs.test-strategy }}"
          echo "📁 Files: ${{ needs.pre-test-analysis.outputs.file-count }}"
          echo "🎪 Test type: ${{ matrix.test-type }}"
          echo ""

      - name: 📥 Repository Checkout
        uses: actions/checkout@v4

      - name: ⚙️ Node.js Environment Setup
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: 📦 Dependency Installation
        run: |
          echo "📦 **INSTALLING PROJECT DEPENDENCIES**"
          npm ci --prefer-offline --no-audit
          echo "✅ Dependencies installed successfully"

      - name: 🎭 Playwright Browser Setup
        if: matrix.test-type != 'unit'
        run: |
          echo "🎭 **INSTALLING PLAYWRIGHT BROWSERS**"
          npx playwright install --with-deps
          echo "✅ Playwright browsers installed"

      - name: 🧪 Unit Test Execution
        if: matrix.test-type == 'unit'
        run: |
          echo "🧪 **EXECUTING UNIT TESTS**"
          echo "🔬 Running isolated unit test suite..."
          npm run test:unit 2>&1 | tee unit-test-output.log || {
            echo "❌ Unit tests failed"
            exit 1
          }
          echo "✅ Unit tests completed successfully"

      - name: 🎯 E2E Test Execution
        if: matrix.test-type == 'e2e'
        run: |
          echo "🎯 **EXECUTING END-TO-END TESTS**"
          echo "🌐 Testing complete user workflows..."
          npm run test:e2e 2>&1 | tee e2e-test-output.log || {
            echo "❌ E2E tests failed"
            exit 1
          }
          echo "✅ E2E tests completed successfully"

      - name: ♿ Accessibility Test Execution
        if: matrix.test-type == 'accessibility'
        run: |
          echo "♿ **EXECUTING ACCESSIBILITY TESTS**"
          echo "🔍 Validating WCAG compliance..."
          npm run test:accessibility 2>&1 | tee accessibility-test-output.log || {
            echo "❌ Accessibility tests failed"
            exit 1
          }
          echo "✅ Accessibility tests completed successfully"

      - name: 📱 Mobile Responsiveness Test Execution
        if: matrix.test-type == 'mobile'
        run: |
          echo "📱 **EXECUTING MOBILE RESPONSIVENESS TESTS**"
          echo "📐 Testing responsive design across devices..."
          npm run test:mobile 2>&1 | tee mobile-test-output.log || {
            echo "❌ Mobile tests failed"
            exit 1
          }
          echo "✅ Mobile tests completed successfully"

      - name: 📊 Test Results Processing
        if: always()
        run: |
          echo "📊 **PROCESSING TEST RESULTS**"
          echo "Test type: ${{ matrix.test-type }}"
          echo "Status: ${{ job.status }}"
          
          # Create test results summary
          if [ -f "${{ matrix.test-type }}-test-output.log" ]; then
            echo "📝 Log file created: ${{ matrix.test-type }}-test-output.log"
            echo "📏 Log size: $(wc -l < ${{ matrix.test-type }}-test-output.log) lines"
          fi

      - name: 📁 Upload Test Artifacts
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: test-results-${{ matrix.test-type }}
          path: |
            playwright-report/
            test-results/
            *-test-output.log
          retention-days: 30

      - name: 📋 Live Test Console Output
        if: always()
        run: |
          echo "🖥️ **RENDERING TEST CONSOLE TO WORKFLOW SUMMARY**"
          
          if [ -f "${{ matrix.test-type }}-test-output.log" ]; then
            echo "## 🧪 ${{ matrix.test-type }} Test Output" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            tail -50 "${{ matrix.test-type }}-test-output.log" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi

  lighthouse:
    name: ⚡ Performance Analysis Excellence  
    runs-on: ubuntu-latest
    needs: [pre-test-analysis, test]
    if: needs.pre-test-analysis.outputs.test-strategy != 'quick'
    steps:
      - name: 🚀 Performance Analysis Initialization
        run: |
          echo "⚡ **PERFORMANCE ANALYSIS INITIATED**"
          echo "📊 Strategy: ${{ needs.pre-test-analysis.outputs.test-strategy }}"
          echo "🎯 Target: Lighthouse CI comprehensive analysis"
          echo "📈 Metrics: Performance, Accessibility, Best Practices, SEO"
          echo ""

      - name: 📥 Repository Checkout
        uses: actions/checkout@v4

      - name: ⚙️ Node.js Environment Setup
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: 📦 Dependency Installation
        run: |
          echo "📦 **INSTALLING PROJECT DEPENDENCIES**"
          npm ci --prefer-offline --no-audit
          echo "✅ Dependencies installed successfully"

      - name: 🚀 Lighthouse CI Performance Analysis
        run: |
          echo "🚀 **EXECUTING LIGHTHOUSE CI ANALYSIS**"
          echo "📊 Analyzing performance, accessibility, and best practices..."
          npm run lhci 2>&1 | tee lighthouse-output.log || {
            echo "⚠️ Lighthouse CI completed with warnings or issues"
            echo "📋 See detailed report above"
          }
          echo "✅ Performance analysis completed"

      - name: 📊 Performance Metrics Processing
        if: always()
        run: |
          echo "📊 **PROCESSING PERFORMANCE METRICS**"
          
          if [ -f "lighthouse-output.log" ]; then
            echo "📈 **Performance Summary:**"
            grep -E "(Performance|Accessibility|Best Practices|SEO)" lighthouse-output.log || echo "No standard metrics found"
            echo ""
            
            echo "📏 Log size: $(wc -l < lighthouse-output.log) lines"
          fi

      - name: 📋 Live Performance Console Output
        if: always()
        run: |
          echo "🖥️ **RENDERING PERFORMANCE RESULTS TO WORKFLOW SUMMARY**"
          
          if [ -f "lighthouse-output.log" ]; then
            echo "## ⚡ Lighthouse Performance Analysis" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            tail -100 "lighthouse-output.log" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 📁 Upload Performance Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-results
          path: |
            .lighthouseci/
            lighthouse-output.log
          retention-days: 30

  test-summary:
    name: 📋 Comprehensive Test Summary
    runs-on: ubuntu-latest
    needs: [pre-test-analysis, lint, test, lighthouse]
    if: always()
    steps:
      - name: 🎉 Test Suite Completion
        run: |
          echo "🏁 **COMPREHENSIVE TEST SUITE COMPLETED**"
          echo "📅 Completed at: $(date +'%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          
          echo "📊 **Final Results Summary:**"
          echo "✅ Pre-analysis: ${{ needs.pre-test-analysis.result }}"
          echo "✅ Code Quality: ${{ needs.lint.result }}"
          echo "✅ Test Suite: ${{ needs.test.result }}"
          echo "✅ Performance: ${{ needs.lighthouse.result }}"
          echo ""
          
          # Determine overall status
          if [ "${{ needs.lint.result }}" = "success" ] && [ "${{ needs.test.result }}" = "success" ]; then
            echo "🎉 **ALL TESTS PASSED!** 🎉"
            echo "✨ Code quality and functionality verified"
            echo "🚀 Ready for deployment"
          else
            echo "❌ **SOME TESTS FAILED**"
            echo "🔍 Review failed jobs and address issues"
            echo "📋 Check individual job logs for details"
          fi

      - name: 📊 Comprehensive Workflow Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # 🧪 Comprehensive Test Suite Results
          
          ## 📊 Execution Overview
          - **Strategy:** ${{ needs.pre-test-analysis.outputs.test-strategy }}
          - **Files Analyzed:** ${{ needs.pre-test-analysis.outputs.file-count }}
          - **Complexity Score:** ${{ needs.pre-test-analysis.outputs.complexity-score }}
          - **Duration:** Started at workflow initiation, completed at $(date +'%H:%M:%S UTC')
          
          ## 🎯 Test Results Matrix
          | Component | Status | Details |
          |-----------|---------|---------|
          | 📊 Pre-Analysis | ${{ needs.pre-test-analysis.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | Codebase complexity analysis |
          | 🔍 Code Quality | ${{ needs.lint.result == 'success' && '✅ PASSED' || '❌ FAILED' }} | ESLint, Prettier, Stylelint |
          | 🧪 Unit Tests | ${{ contains(needs.test.result, 'success') && '✅ PASSED' || '❌ FAILED' }} | Isolated component testing |
          | 🎯 E2E Tests | ${{ contains(needs.test.result, 'success') && '✅ PASSED' || '❌ FAILED' }} | End-to-end workflow testing |
          | ♿ Accessibility | ${{ contains(needs.test.result, 'success') && '✅ PASSED' || '❌ FAILED' }} | WCAG compliance validation |
          | 📱 Mobile Tests | ${{ contains(needs.test.result, 'success') && '✅ PASSED' || '❌ FAILED' }} | Responsive design testing |
          | ⚡ Performance | ${{ needs.lighthouse.result == 'success' && '✅ PASSED' || needs.lighthouse.result == 'skipped' && '⏭️ SKIPPED' || '⚠️ WARNINGS' }} | Lighthouse CI analysis |
          
          ## 🚀 Quality Metrics
          - **Code Standards:** Enterprise-grade linting and formatting
          - **Test Coverage:** Multi-dimensional testing approach
          - **Performance:** Lighthouse CI comprehensive analysis
          - **Accessibility:** WCAG AA compliance validation
          - **Mobile:** Cross-device responsiveness testing
          
          ${{ (needs.lint.result == 'success' && contains(needs.test.result, 'success')) && '## 🎉 All Tests Passed!\n\n✨ **Excellent work!** Your code meets all quality standards and is ready for deployment.\n\n🚀 **Next Steps:**\n- Merge with confidence\n- Deploy to staging/production\n- Monitor performance metrics' || '## ⚠️ Action Required\n\n🔍 **Some tests failed or have warnings.** Please review the individual job logs and address any issues before proceeding.\n\n🛠️ **Troubleshooting:**\n- Check ESLint/Prettier issues in Code Quality job\n- Review test failures in Test Suite jobs\n- Address performance concerns in Lighthouse results' }}
          EOF

      - name: 📝 Commit CI Logs
        if: always()
        run: |
          if [ -f "${{ env.ci_log_file }}" ]; then
            echo "📝 **COMMITTING CI LOGS TO REPOSITORY**"
            
            # Finalize log file
            {
              echo ""
              echo "🏁 Test Suite Completed: $(date +'%Y-%m-%d %H:%M:%S UTC')"
              echo "✅ Final Status: ${{ job.status }}"
              echo "======================================"
            } >> "${{ env.ci_log_file }}"
            
            # Commit logs
            git config --local user.email "ci-logger@github.com"
            git config --local user.name "CI Logger Bot"
            git add logs/
            
            if ! git diff --cached --quiet; then
              git commit -m "📝 CI Logs: Test Suite $(date +'%Y%m%d-%H%M%S')

              🧪 Comprehensive test suite execution log
              📊 Status: ${{ job.status }}
              🌿 Branch: ${{ github.ref_name }}
              💫 Commit: ${{ github.sha }}

              📁 Log saved: ${{ env.ci_log_file }}"
              
              git push || echo "⚠️ Could not push logs (likely due to permissions)"
            else
              echo "📝 No log changes to commit"
            fi
          fi
