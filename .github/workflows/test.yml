name: ğŸ§ª Comprehensive Test Suite Excellence

on:
  pull_request:
    branches: [ main ]
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test coverage level'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - quick
          - performance-only

env:
  CI: true
  NODE_ENV: test

jobs:
  pre-test-analysis:
    name: ğŸ“Š Pre-Test Analysis & Setup
    runs-on: ubuntu-latest
    outputs:
      test-strategy: ${{ steps.strategy.outputs.strategy }}
      file-count: ${{ steps.analysis.outputs.file-count }}
      complexity-score: ${{ steps.analysis.outputs.complexity }}
    steps:
      - name: ğŸš€ Test Suite Initialization
        run: |
          echo "ğŸ§ª **COMPREHENSIVE TEST SUITE INITIATED**"
          echo "ğŸ“… Started at: $(date +'%Y-%m-%d %H:%M:%S UTC')"
          echo "ğŸ¯ Test level: ${{ github.event.inputs.test_level || 'full' }}"
          echo "ğŸŒ¿ Branch: ${{ github.ref_name }}"
          echo "ğŸ’« Commit: ${{ github.sha }}"
          echo "ğŸ¤– Triggered by: ${{ github.event_name }}"
          echo ""
          
          # Initialize CI logging
          mkdir -p logs/ci
          LOG_FILE="logs/ci/test-suite-$(date +'%Y%m%d-%H%M%S').log"
          echo "ğŸ“ Initializing CI log: $LOG_FILE"
          
          {
            echo "ğŸ§ª COMPREHENSIVE TEST SUITE LOG"
            echo "======================================"
            echo "ğŸ“… Started: $(date +'%Y-%m-%d %H:%M:%S UTC')"
            echo "ğŸ¯ Test level: ${{ github.event.inputs.test_level || 'full' }}"
            echo "ğŸŒ¿ Branch: ${{ github.ref_name }}"
            echo "ğŸ’« Commit: ${{ github.sha }}"
            echo "ğŸ¤– Triggered by: ${{ github.event_name }}"
            echo ""
          } > "$LOG_FILE"
          
          echo "ci_log_file=$LOG_FILE" >> $GITHUB_ENV

      - name: ğŸ“¥ Repository Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: ğŸ” Codebase Analysis
        id: analysis
        run: |
          echo "ğŸ”¬ **ANALYZING CODEBASE COMPLEXITY**"
          
          # Count different file types
          JS_FILES=$(find . -name "*.js" -not -path "./node_modules/*" | wc -l)
          TS_FILES=$(find . -name "*.ts" -not -path "./node_modules/*" | wc -l)
          CSS_FILES=$(find . -name "*.css" -not -path "./node_modules/*" | wc -l)
          HTML_FILES=$(find . -name "*.html" -not -path "./node_modules/*" | wc -l)
          TEST_FILES=$(find . -name "*.test.*" -o -name "*.spec.*" -not -path "./node_modules/*" | wc -l)
          
          TOTAL_FILES=$((JS_FILES + TS_FILES + CSS_FILES + HTML_FILES))
          
          echo "ğŸ“ **File Analysis:**"
          echo "  - JavaScript files: $JS_FILES"
          echo "  - TypeScript files: $TS_FILES" 
          echo "  - CSS files: $CSS_FILES"
          echo "  - HTML files: $HTML_FILES"
          echo "  - Test files: $TEST_FILES"
          echo "  - Total source files: $TOTAL_FILES"
          
          # Calculate complexity score (simple heuristic)
          COMPLEXITY_SCORE=$((TOTAL_FILES * 2 + TEST_FILES * 3))
          
          echo "ğŸ“Š Complexity score: $COMPLEXITY_SCORE"
          echo "file-count=$TOTAL_FILES" >> $GITHUB_OUTPUT
          echo "complexity=$COMPLEXITY_SCORE" >> $GITHUB_OUTPUT
          echo ""

      - name: ğŸ¯ Test Strategy Selection
        id: strategy
        run: |
          echo "ğŸ² **DETERMINING OPTIMAL TEST STRATEGY**"
          
          COMPLEXITY=${{ steps.analysis.outputs.complexity }}
          TEST_LEVEL="${{ github.event.inputs.test_level || 'full' }}"
          
          if [ "$TEST_LEVEL" = "quick" ] || [ "$COMPLEXITY" -lt 50 ]; then
            STRATEGY="quick"
            echo "âš¡ Selected: Quick test strategy (complexity: $COMPLEXITY)"
          elif [ "$TEST_LEVEL" = "performance-only" ]; then
            STRATEGY="performance"
            echo "ğŸ“ˆ Selected: Performance-only strategy"
          else
            STRATEGY="comprehensive"
            echo "ğŸ”¬ Selected: Comprehensive test strategy (complexity: $COMPLEXITY)"
          fi
          
          echo "strategy=$STRATEGY" >> $GITHUB_OUTPUT
          echo ""

  lint:
    name: ğŸ” Code Quality & Standards
    runs-on: ubuntu-latest
    needs: pre-test-analysis
    steps:
      - name: ğŸ¨ Linting Phase Initialization
        run: |
          echo "ğŸ” **CODE QUALITY ANALYSIS INITIATED**"
          echo "ğŸ“Š Analyzing ${{ needs.pre-test-analysis.outputs.file-count }} source files"
          echo "ğŸ¯ Complexity score: ${{ needs.pre-test-analysis.outputs.complexity-score }}"
          echo ""

      - name: ğŸ“¥ Repository Checkout
        uses: actions/checkout@v4

      - name: âš™ï¸ Node.js Environment Setup
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: ğŸ“¦ Dependency Installation
        run: |
          echo "ğŸ“¦ **INSTALLING PROJECT DEPENDENCIES**"
          npm ci --prefer-offline --no-audit
          echo "âœ… Dependencies installed successfully"
          echo ""

      - name: ğŸ” ESLint Analysis
        run: |
          echo "ğŸ” **RUNNING ESLINT ANALYSIS**"
          echo "ğŸ“‹ Checking JavaScript/TypeScript code quality..."
          npm run lint 2>&1 | tee eslint-output.log || {
            echo "âŒ ESLint found issues - see details above"
            exit 1
          }
          echo "âœ… ESLint analysis completed successfully"
          echo ""
          
          # Log to persistent file
          {
            echo "ğŸ” ESLint Analysis: SUCCESS"
            echo "ğŸ“… $(date +'%Y-%m-%d %H:%M:%S UTC')"
            echo "ğŸ“Š Files analyzed: JavaScript/TypeScript"
            echo ""
          } >> "${{ env.ci_log_file }}"

      - name: âœ¨ Code Formatting Validation
        run: |
          echo "âœ¨ **VALIDATING CODE FORMATTING**"
          echo "ğŸ“ Checking Prettier formatting compliance..."
          npm run format-check 2>&1 | tee prettier-output.log || {
            echo "âŒ Code formatting issues detected"
            echo "ğŸ’¡ Run 'npm run format' to fix formatting"
            exit 1
          }
          echo "âœ… Code formatting validation passed"
          echo ""

      - name: ğŸ¨ CSS Lint Validation
        run: |
          echo "ğŸ¨ **VALIDATING CSS STYLES**"
          echo "ğŸ–Œï¸ Checking CSS/SCSS style compliance..."
          npm run lint:css 2>&1 | tee stylelint-output.log || {
            echo "âŒ CSS linting issues detected"
            exit 1
          }
          echo "âœ… CSS validation completed successfully"
          echo ""

      - name: ğŸ“Š Linting Summary
        if: always()
        run: |
          echo "ğŸ“‹ **CODE QUALITY SUMMARY**"
          echo "âœ… ESLint: ${{ job.steps.eslint.outcome == 'success' && 'PASSED' || 'FAILED' }}"
          echo "âœ… Prettier: ${{ job.steps.prettier.outcome == 'success' && 'PASSED' || 'FAILED' }}"  
          echo "âœ… Stylelint: ${{ job.steps.stylelint.outcome == 'success' && 'PASSED' || 'FAILED' }}"
          echo ""
      
  test:
    name: ğŸš€ Comprehensive Testing Suite
    runs-on: ubuntu-latest
    needs: [pre-test-analysis, lint]
    strategy:
      matrix:
        test-type: [unit, e2e, accessibility, mobile]
      fail-fast: false
    steps:
      - name: ğŸ¯ Test Phase Initialization
        run: |
          echo "ğŸ§ª **${{ matrix.test-type }} TESTING PHASE INITIATED**"
          echo "ğŸ“Š Strategy: ${{ needs.pre-test-analysis.outputs.test-strategy }}"
          echo "ğŸ“ Files: ${{ needs.pre-test-analysis.outputs.file-count }}"
          echo "ğŸª Test type: ${{ matrix.test-type }}"
          echo ""

      - name: ğŸ“¥ Repository Checkout
        uses: actions/checkout@v4

      - name: âš™ï¸ Node.js Environment Setup
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: ğŸ“¦ Dependency Installation
        run: |
          echo "ğŸ“¦ **INSTALLING PROJECT DEPENDENCIES**"
          npm ci --prefer-offline --no-audit
          echo "âœ… Dependencies installed successfully"

      - name: ğŸ­ Playwright Browser Setup
        if: matrix.test-type != 'unit'
        run: |
          echo "ğŸ­ **INSTALLING PLAYWRIGHT BROWSERS**"
          npx playwright install --with-deps
          echo "âœ… Playwright browsers installed"

      - name: ğŸ§ª Unit Test Execution
        if: matrix.test-type == 'unit'
        run: |
          echo "ğŸ§ª **EXECUTING UNIT TESTS**"
          echo "ğŸ”¬ Running isolated unit test suite..."
          npm run test:unit 2>&1 | tee unit-test-output.log || {
            echo "âŒ Unit tests failed"
            exit 1
          }
          echo "âœ… Unit tests completed successfully"

      - name: ğŸ¯ E2E Test Execution
        if: matrix.test-type == 'e2e'
        run: |
          echo "ğŸ¯ **EXECUTING END-TO-END TESTS**"
          echo "ğŸŒ Testing complete user workflows..."
          npm run test:e2e 2>&1 | tee e2e-test-output.log || {
            echo "âŒ E2E tests failed"
            exit 1
          }
          echo "âœ… E2E tests completed successfully"

      - name: â™¿ Accessibility Test Execution
        if: matrix.test-type == 'accessibility'
        run: |
          echo "â™¿ **EXECUTING ACCESSIBILITY TESTS**"
          echo "ğŸ” Validating WCAG compliance..."
          npm run test:accessibility 2>&1 | tee accessibility-test-output.log || {
            echo "âŒ Accessibility tests failed"
            exit 1
          }
          echo "âœ… Accessibility tests completed successfully"

      - name: ğŸ“± Mobile Responsiveness Test Execution
        if: matrix.test-type == 'mobile'
        run: |
          echo "ğŸ“± **EXECUTING MOBILE RESPONSIVENESS TESTS**"
          echo "ğŸ“ Testing responsive design across devices..."
          npm run test:mobile 2>&1 | tee mobile-test-output.log || {
            echo "âŒ Mobile tests failed"
            exit 1
          }
          echo "âœ… Mobile tests completed successfully"

      - name: ğŸ“Š Test Results Processing
        if: always()
        run: |
          echo "ğŸ“Š **PROCESSING TEST RESULTS**"
          echo "Test type: ${{ matrix.test-type }}"
          echo "Status: ${{ job.status }}"
          
          # Create test results summary
          if [ -f "${{ matrix.test-type }}-test-output.log" ]; then
            echo "ğŸ“ Log file created: ${{ matrix.test-type }}-test-output.log"
            echo "ğŸ“ Log size: $(wc -l < ${{ matrix.test-type }}-test-output.log) lines"
          fi

      - name: ğŸ“ Upload Test Artifacts
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: test-results-${{ matrix.test-type }}
          path: |
            playwright-report/
            test-results/
            *-test-output.log
          retention-days: 30

      - name: ğŸ“‹ Live Test Console Output
        if: always()
        run: |
          echo "ğŸ–¥ï¸ **RENDERING TEST CONSOLE TO WORKFLOW SUMMARY**"
          
          if [ -f "${{ matrix.test-type }}-test-output.log" ]; then
            echo "## ğŸ§ª ${{ matrix.test-type }} Test Output" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            tail -50 "${{ matrix.test-type }}-test-output.log" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi

  lighthouse:
    name: âš¡ Performance Analysis Excellence  
    runs-on: ubuntu-latest
    needs: [pre-test-analysis, test]
    if: needs.pre-test-analysis.outputs.test-strategy != 'quick'
    steps:
      - name: ğŸš€ Performance Analysis Initialization
        run: |
          echo "âš¡ **PERFORMANCE ANALYSIS INITIATED**"
          echo "ğŸ“Š Strategy: ${{ needs.pre-test-analysis.outputs.test-strategy }}"
          echo "ğŸ¯ Target: Lighthouse CI comprehensive analysis"
          echo "ğŸ“ˆ Metrics: Performance, Accessibility, Best Practices, SEO"
          echo ""

      - name: ğŸ“¥ Repository Checkout
        uses: actions/checkout@v4

      - name: âš™ï¸ Node.js Environment Setup
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: ğŸ“¦ Dependency Installation
        run: |
          echo "ğŸ“¦ **INSTALLING PROJECT DEPENDENCIES**"
          npm ci --prefer-offline --no-audit
          echo "âœ… Dependencies installed successfully"

      - name: ğŸš€ Lighthouse CI Performance Analysis
        run: |
          echo "ğŸš€ **EXECUTING LIGHTHOUSE CI ANALYSIS**"
          echo "ğŸ“Š Analyzing performance, accessibility, and best practices..."
          npm run lhci 2>&1 | tee lighthouse-output.log || {
            echo "âš ï¸ Lighthouse CI completed with warnings or issues"
            echo "ğŸ“‹ See detailed report above"
          }
          echo "âœ… Performance analysis completed"

      - name: ğŸ“Š Performance Metrics Processing
        if: always()
        run: |
          echo "ğŸ“Š **PROCESSING PERFORMANCE METRICS**"
          
          if [ -f "lighthouse-output.log" ]; then
            echo "ğŸ“ˆ **Performance Summary:**"
            grep -E "(Performance|Accessibility|Best Practices|SEO)" lighthouse-output.log || echo "No standard metrics found"
            echo ""
            
            echo "ğŸ“ Log size: $(wc -l < lighthouse-output.log) lines"
          fi

      - name: ğŸ“‹ Live Performance Console Output
        if: always()
        run: |
          echo "ğŸ–¥ï¸ **RENDERING PERFORMANCE RESULTS TO WORKFLOW SUMMARY**"
          
          if [ -f "lighthouse-output.log" ]; then
            echo "## âš¡ Lighthouse Performance Analysis" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            tail -100 "lighthouse-output.log" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ğŸ“ Upload Performance Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-results
          path: |
            .lighthouseci/
            lighthouse-output.log
          retention-days: 30

  test-summary:
    name: ğŸ“‹ Comprehensive Test Summary
    runs-on: ubuntu-latest
    needs: [pre-test-analysis, lint, test, lighthouse]
    if: always()
    steps:
      - name: ğŸ‰ Test Suite Completion
        run: |
          echo "ğŸ **COMPREHENSIVE TEST SUITE COMPLETED**"
          echo "ğŸ“… Completed at: $(date +'%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          
          echo "ğŸ“Š **Final Results Summary:**"
          echo "âœ… Pre-analysis: ${{ needs.pre-test-analysis.result }}"
          echo "âœ… Code Quality: ${{ needs.lint.result }}"
          echo "âœ… Test Suite: ${{ needs.test.result }}"
          echo "âœ… Performance: ${{ needs.lighthouse.result }}"
          echo ""
          
          # Determine overall status
          if [ "${{ needs.lint.result }}" = "success" ] && [ "${{ needs.test.result }}" = "success" ]; then
            echo "ğŸ‰ **ALL TESTS PASSED!** ğŸ‰"
            echo "âœ¨ Code quality and functionality verified"
            echo "ğŸš€ Ready for deployment"
          else
            echo "âŒ **SOME TESTS FAILED**"
            echo "ğŸ” Review failed jobs and address issues"
            echo "ğŸ“‹ Check individual job logs for details"
          fi

      - name: ğŸ“Š Comprehensive Workflow Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # ğŸ§ª Comprehensive Test Suite Results
          
          ## ğŸ“Š Execution Overview
          - **Strategy:** ${{ needs.pre-test-analysis.outputs.test-strategy }}
          - **Files Analyzed:** ${{ needs.pre-test-analysis.outputs.file-count }}
          - **Complexity Score:** ${{ needs.pre-test-analysis.outputs.complexity-score }}
          - **Duration:** Started at workflow initiation, completed at $(date +'%H:%M:%S UTC')
          
          ## ğŸ¯ Test Results Matrix
          | Component | Status | Details |
          |-----------|---------|---------|
          | ğŸ“Š Pre-Analysis | ${{ needs.pre-test-analysis.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }} | Codebase complexity analysis |
          | ğŸ” Code Quality | ${{ needs.lint.result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }} | ESLint, Prettier, Stylelint |
          | ğŸ§ª Unit Tests | ${{ contains(needs.test.result, 'success') && 'âœ… PASSED' || 'âŒ FAILED' }} | Isolated component testing |
          | ğŸ¯ E2E Tests | ${{ contains(needs.test.result, 'success') && 'âœ… PASSED' || 'âŒ FAILED' }} | End-to-end workflow testing |
          | â™¿ Accessibility | ${{ contains(needs.test.result, 'success') && 'âœ… PASSED' || 'âŒ FAILED' }} | WCAG compliance validation |
          | ğŸ“± Mobile Tests | ${{ contains(needs.test.result, 'success') && 'âœ… PASSED' || 'âŒ FAILED' }} | Responsive design testing |
          | âš¡ Performance | ${{ needs.lighthouse.result == 'success' && 'âœ… PASSED' || needs.lighthouse.result == 'skipped' && 'â­ï¸ SKIPPED' || 'âš ï¸ WARNINGS' }} | Lighthouse CI analysis |
          
          ## ğŸš€ Quality Metrics
          - **Code Standards:** Enterprise-grade linting and formatting
          - **Test Coverage:** Multi-dimensional testing approach
          - **Performance:** Lighthouse CI comprehensive analysis
          - **Accessibility:** WCAG AA compliance validation
          - **Mobile:** Cross-device responsiveness testing
          
          ${{ (needs.lint.result == 'success' && contains(needs.test.result, 'success')) && '## ğŸ‰ All Tests Passed!\n\nâœ¨ **Excellent work!** Your code meets all quality standards and is ready for deployment.\n\nğŸš€ **Next Steps:**\n- Merge with confidence\n- Deploy to staging/production\n- Monitor performance metrics' || '## âš ï¸ Action Required\n\nğŸ” **Some tests failed or have warnings.** Please review the individual job logs and address any issues before proceeding.\n\nğŸ› ï¸ **Troubleshooting:**\n- Check ESLint/Prettier issues in Code Quality job\n- Review test failures in Test Suite jobs\n- Address performance concerns in Lighthouse results' }}
          EOF

      - name: ğŸ“ Commit CI Logs
        if: always()
        run: |
          if [ -f "${{ env.ci_log_file }}" ]; then
            echo "ğŸ“ **COMMITTING CI LOGS TO REPOSITORY**"
            
            # Finalize log file
            {
              echo ""
              echo "ğŸ Test Suite Completed: $(date +'%Y-%m-%d %H:%M:%S UTC')"
              echo "âœ… Final Status: ${{ job.status }}"
              echo "======================================"
            } >> "${{ env.ci_log_file }}"
            
            # Commit logs
            git config --local user.email "ci-logger@github.com"
            git config --local user.name "CI Logger Bot"
            git add logs/
            
            if ! git diff --cached --quiet; then
              git commit -m "ğŸ“ CI Logs: Test Suite $(date +'%Y%m%d-%H%M%S')

              ğŸ§ª Comprehensive test suite execution log
              ğŸ“Š Status: ${{ job.status }}
              ğŸŒ¿ Branch: ${{ github.ref_name }}
              ğŸ’« Commit: ${{ github.sha }}

              ğŸ“ Log saved: ${{ env.ci_log_file }}"
              
              git push || echo "âš ï¸ Could not push logs (likely due to permissions)"
            else
              echo "ğŸ“ No log changes to commit"
            fi
          fi
